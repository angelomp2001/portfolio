{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JGKu6CciKwb"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "# def upload(uploaded_file_dict):\n",
        "#     try:\n",
        "#         # Extract the file name and content\n",
        "#         file_name = next(iter(uploaded_file_dict))\n",
        "#         file_content = uploaded_file_dict[file_name]\n",
        "\n",
        "#         # Attempt to read the CSV file\n",
        "#         df = pd.read_csv(io.BytesIO(file_content), sep=',', encoding='utf-8')\n",
        "#         print(f'✅ File loaded successfully! → {file_name}')\n",
        "#         return df\n",
        "\n",
        "#     except pd.errors.ParserError as e:\n",
        "#         print(\"❌ Parsing Error: The file contains lines that can't be interpreted as valid CSV.\")\n",
        "#         print(f\"Technical details: {e}\")\n",
        "\n",
        "#     except UnicodeDecodeError as e:\n",
        "#         print(\"❌ Encoding Error: The file might not be UTF-8 encoded.\")\n",
        "#         print(\"Try saving it as UTF-8 and re-uploading.\")\n",
        "#         print(f\"Technical details: {e}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(\"❌ An unexpected error occurred while trying to read the file.\")\n",
        "#         print(f\"Technical details: {e}\")\n",
        "\n",
        "#     return None  # In case of error\n",
        "\n",
        "# # upload dataset and save as df\n",
        "# uploaded = files.upload()\n",
        "df = pd.read_csv('games.csv')\n",
        "\n",
        "#view df\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', 500)        # Increase horizontal width\n",
        "pd.set_option('display.max_colwidth', None) # Show full content of each column\n",
        "\n",
        "def view(dfs, view=None):\n",
        "    # Convert input to a dictionary of DataFrames if needed\n",
        "    if isinstance(dfs, pd.DataFrame):\n",
        "        dfs = {'df': dfs}  # Wrap single DataFrame in a dict with a default name\n",
        "    elif isinstance(dfs, pd.Series):\n",
        "        series_name = dfs.name if dfs.name is not None else 'Series'\n",
        "        dfs = {series_name: dfs.to_frame()}\n",
        "    else:\n",
        "        print(\"Input must be a pandas DataFrame or Series.\")\n",
        "        return\n",
        "\n",
        "    views = {\n",
        "        \"headers\": [],\n",
        "        \"values\": [],\n",
        "        \"missing values\": [],\n",
        "        \"dtypes\": [],\n",
        "        \"summaries\": []\n",
        "    }\n",
        "\n",
        "    missing_cols = []\n",
        "\n",
        "    for df_name, df in dfs.items():\n",
        "        for col in df.columns:\n",
        "            # Ensure we don't fail on empty columns\n",
        "            counts = df[col].value_counts()\n",
        "            common_unique_values = counts.head(5).index.tolist() if not counts.empty else []\n",
        "            rare_unique_values = df[col].value_counts(sort=False).head(5).index.tolist() if not counts.empty else []\n",
        "            if df[col].count() > 0:\n",
        "                data_type = type(df[col].iloc[0])\n",
        "            else:\n",
        "                data_type = np.nan\n",
        "\n",
        "            series_count = df[col].count()\n",
        "            no_values = len(df) - series_count\n",
        "            total = no_values + series_count\n",
        "            no_values_percent = (no_values / total) * 100 if total != 0 else 0\n",
        "\n",
        "            views[\"headers\"].append({\n",
        "                'DataFrame': f'{df_name}',\n",
        "                'Column': col,\n",
        "                'Common Values': common_unique_values,\n",
        "            })\n",
        "\n",
        "            views[\"values\"].append({\n",
        "                'DataFrame': f'{df_name}',\n",
        "                'Column': col,\n",
        "                'Rare Values': rare_unique_values,\n",
        "            })\n",
        "\n",
        "            views[\"missing values\"].append({\n",
        "                'DataFrame': f'{df_name}',\n",
        "                'Column': col,\n",
        "                'Series Count': series_count,\n",
        "                'Missing Values (%)': f'{no_values} ({no_values_percent:.0f}%)'\n",
        "            })\n",
        "\n",
        "            views[\"dtypes\"].append({\n",
        "                'DataFrame': f'{df_name}',\n",
        "                'Column': col,\n",
        "                'Common Values': common_unique_values,\n",
        "                'Data Type': data_type,\n",
        "            })\n",
        "\n",
        "            views[\"summaries\"].append({\n",
        "                'DataFrame': f'{df_name}',\n",
        "                'Column': col,\n",
        "                'Common Values': common_unique_values,\n",
        "                'Rare Values': rare_unique_values,\n",
        "                'Data Type': data_type,\n",
        "                'Series Count': series_count,\n",
        "                'Missing Values': f'{no_values} ({no_values_percent:.0f}%)'\n",
        "            })\n",
        "\n",
        "            if no_values > 0:\n",
        "                missing_cols.append(col)\n",
        "\n",
        "    code = {\n",
        "        'headers': \"# df.rename(columns={col: col.lower() for col in df.columns}, inplace=True)\",\n",
        "        'values': \"# df['column_name'].replace(to_replace='old_value', value=None, inplace=True)\\n# df['col_1'] = df['col_1'].fillna('Unknown', inplace=False)\",\n",
        "        'missing values': f\"# Check for duplicates or summary statistics\\nMissing Columns: {missing_cols}\",\n",
        "        'dtypes': \"# df['col'] = df['col'].astype(str)\\n# df['col'] = pd.to_datetime(df['col'], format='%Y-%m-%dT%H:%M:%SZ')\",\n",
        "        'summaries': f\"DataFrames: {list(dfs.keys())}\"\n",
        "    }\n",
        "\n",
        "    if view is None or view == \"all\":\n",
        "        for view_name, view_data in views.items():\n",
        "            print(f'{view_name}:\\n{pd.DataFrame(view_data)}\\n{code.get(view_name, \"\")}\\n')\n",
        "    elif view in views:\n",
        "        print(f'{view}:\\n{pd.DataFrame(views[view])}\\n{code.get(view, \"\")}\\n')\n",
        "    else:\n",
        "        print(\"Invalid view. Available views are: headers, values, dtypes, missing values, summaries, or all.\")\n",
        "\n",
        "view(df)\n",
        "\n",
        "\n",
        "# make lowercase\n",
        "for col in df.columns:\n",
        "    df.rename(columns={col: col.lower()}, inplace=True)\n",
        "    print(col.lower())\n",
        "\n",
        "# relabel missing\n",
        "view(df, 'missing values') #6701\n",
        "print(f'tbd count: ',(df['user_score'] == 'tbd').sum()) #2424\n",
        "df['user_score'] = df['user_score'].replace(to_replace='tbd', value=None)\n",
        "print('tbd count:',(df['user_score'] == 'tbd').sum()) #0\n",
        "view(df, 'missing values') #9125\n",
        "\n",
        "#adjust dtype\n",
        "#user score.  after fixing tbd above, I need to update it\n",
        "print(\"user_score float:\")\n",
        "df['user_score']= df['user_score'].astype('float64')\n",
        "print(df['user_score'].dtype)\n",
        "\n",
        "#year of release: should be datetime\n",
        "print(\"year_of_release to year format:\")\n",
        "df['year_of_release']= pd.to_datetime(df['year_of_release'], format='%Y')\n",
        "print(df['year_of_release'].dtype)\n",
        "\n",
        "#critic score should be integer\n",
        "print(\"critic score int:\")\n",
        "#print(df['critic_score'].unique())\n",
        "df['critic_score'] = df['critic_score'].astype('Int64')\n",
        "print(df['critic_score'].dtype)\n",
        "\n",
        "#remove duplicates\n",
        "print(\"remove duplicates:\")\n",
        "df.duplicated().sum()\n",
        "df.drop_duplicates()\n",
        "# QC\n",
        "df.duplicated().sum()\n",
        "\n",
        "# Display basic information about the dataset\n",
        "df.info()\n",
        "\n",
        "# Verify the changes\n",
        "print(df.columns)\n",
        "\n",
        "# Check current data types\n",
        "view(df, 'dtypes')\n",
        "df.info()\n",
        "\n",
        "view(df,'values')\n",
        "\n",
        "view(df, 'missing values')\n",
        "\n",
        "# Analyze patterns in missing values\n",
        "#MAR by col\n",
        "missing_cols = ['name', 'year_of_release', 'genre', 'critic_score', 'user_score', 'rating']\n",
        "def analyze(missing_cols):\n",
        "  for missing in missing_cols:\n",
        "    print(f'{missing}: check for constant values in other rows:\\n',\n",
        "          df[df[missing_cols[missing_cols.index(missing)]].isna()]\n",
        "          )\n",
        "analyze(missing_cols)\n",
        "\n",
        "#skipping name because it's only 2 values and I can't guess what they are.\n",
        "#Values found in name, although I noticed row 16711 does not follow this pattern\n",
        "print(df.iloc[183]['year_of_release'])\n",
        "df.at[183,'year_of_release'] = pd.to_datetime('2004-01-01')\n",
        "print(df.iloc[183]['year_of_release'])\n",
        "df.at[377,'year_of_release'] = pd.to_datetime('2004-01-01')\n",
        "df.at[475,'year_of_release'] = pd.to_datetime('2006-01-01')\n",
        "df.at[16373  ,'year_of_release'] = pd.to_datetime('2008-01-01')\n",
        "\n",
        "# genre skip\n",
        "# critic_score, no pattern visible, other than other scores/rating missing\n",
        "# user_score, no pattern visible, other than other scores/rating missing\n",
        "# rating, no pattern visible, other than other scores/rating missing\n",
        "\n",
        "# Total sales across all regions\n",
        "df['total_sales'] = df['na_sales'] + df['eu_sales'] + df['jp_sales'] + df['other_sales']\n",
        "df['total_sales'].describe()\n",
        "df['total_sales'].sum()\n",
        "\n",
        "# DataFrame with game releases by year\n",
        "agg_dict = {\n",
        "    'name': 'count',\n",
        "    'platform': 'count',\n",
        "    'genre': 'count',\n",
        "    'na_sales': 'sum',\n",
        "    'eu_sales': 'sum',\n",
        "    'jp_sales': 'sum',\n",
        "    'other_sales': 'sum',\n",
        "    'critic_score': 'mean',\n",
        "    'user_score': 'mean',\n",
        "    'rating': 'count',\n",
        "    'total_sales': 'sum'\n",
        "}\n",
        "game_releases_by_year = df.groupby('year_of_release').agg(agg_dict)\n",
        "game_releases_by_year.head(5)\n",
        "\n",
        "# average game releases by year\n",
        "agg_dict = {\n",
        "    'name': 'count',\n",
        "    'platform': 'count',\n",
        "    'genre': 'count',\n",
        "    'na_sales': 'mean',\n",
        "    'eu_sales': 'mean',\n",
        "    'jp_sales': 'mean',\n",
        "    'other_sales': 'mean',\n",
        "    'critic_score': 'mean',\n",
        "    'user_score': 'mean',\n",
        "    'rating': 'count',\n",
        "    'total_sales': 'mean'\n",
        "}\n",
        "mean_game_releases_by_year = df.groupby('year_of_release').agg(agg_dict)\n",
        "mean_game_releases_by_year.rename(columns={\n",
        "    'na_sales': 'mean_na_sales',\n",
        "    'eu_sales': 'mean_eu_sales',\n",
        "    'jp_sales': 'mean_jp_sales',\n",
        "    'other_sales': 'mean_other_sales',\n",
        "    'total_sales': 'mean_total_sales'\n",
        "}, inplace = True)\n",
        "mean_game_releases_by_year.head(5)\n",
        "\n",
        "# Visualization of the distribution of games across years\n",
        "def see(col, x=None):\n",
        "    # Determine the x-axis label based on the provided argument or index name\n",
        "    if x is None:\n",
        "        x_label = col.index.name or \"Index\"\n",
        "    else:\n",
        "        x_label = x\n",
        "\n",
        "    # For a DataFrame, let pandas use the index without forcing an x column\n",
        "    if isinstance(col, pd.DataFrame):\n",
        "        ax = col.plot(\n",
        "            kind='line',\n",
        "            figsize=(12, 6),\n",
        "            title=f\"{', '.join(col.columns)} by {x_label}\",\n",
        "            grid=True\n",
        "        )\n",
        "        ax.set_xlabel(x_label)\n",
        "        ax.set_ylabel(\"Value\")\n",
        "    else:\n",
        "        # For a Series, plot normally\n",
        "        ax = col.plot(\n",
        "            kind='line',\n",
        "            figsize=(12, 6),\n",
        "            title=f'{col.name} by {x_label}',\n",
        "            grid=True\n",
        "        )\n",
        "        ax.set_xlabel(x_label)\n",
        "        ax.set_ylabel(col.name)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Assuming game_releases_by_year is your DataFrame\n",
        "see(game_releases_by_year['name'])\n",
        "see(game_releases_by_year[['na_sales','eu_sales','jp_sales','other_sales','total_sales']])\n",
        "see(mean_game_releases_by_year[['mean_na_sales','mean_eu_sales','mean_jp_sales','mean_other_sales']])\n",
        "\n",
        "# Summary statistics for each year\n",
        "#summary assuming normal\n",
        "agg_dict = {\n",
        "    'name': 'count',\n",
        "    'platform': 'count',\n",
        "    'genre': 'count',\n",
        "    'na_sales': ['mean', 'std'],\n",
        "    'eu_sales': ['mean', 'std'],\n",
        "    'jp_sales': ['mean', 'std'],\n",
        "    'other_sales': ['mean', 'std'],\n",
        "    'critic_score': ['mean', 'std'],\n",
        "    'user_score': ['mean', 'std'],\n",
        "    'rating': 'count',\n",
        "    'total_sales': ['mean', 'std']\n",
        "}\n",
        "game_releases_by_year_normal = df.groupby('year_of_release').agg(agg_dict)\n",
        "\n",
        "#summary assuming skewed\n",
        "def quantile_25(x):\n",
        "  return x.quantile(0.25)\n",
        "\n",
        "def quantile_75(x):\n",
        "  return x.quantile(0.75)\n",
        "\n",
        "\n",
        "agg_dict = {\n",
        "    'name': 'count',\n",
        "    'platform': 'count',\n",
        "    'genre': 'count',\n",
        "    'na_sales': ['median', ('q1', quantile_25), ('q3', quantile_75)],\n",
        "    'eu_sales': ['median', ('q1', quantile_25), ('q3', quantile_75)],\n",
        "    'jp_sales': ['median', ('q1', quantile_25), ('q3', quantile_75)],\n",
        "    'other_sales': ['median', ('q1', quantile_25), ('q3', quantile_75)],\n",
        "    'critic_score': ['median', ('q1', quantile_25), ('q3', quantile_75)],\n",
        "    'user_score': ['median', ('q1', quantile_25), ('q3', quantile_75)],\n",
        "    'rating': 'count',\n",
        "    'total_sales': ['median', ('q1', quantile_25), ('q3', quantile_75)]\n",
        "}\n",
        "game_releases_by_year_skewed = df.groupby('year_of_release').agg(agg_dict)\n",
        "\n",
        "# Left: Line plot\n",
        "#years = game_releases_by_year_normal.index\n",
        "mean_sales = game_releases_by_year_normal[('total_sales', 'mean')]\n",
        "std_sales = game_releases_by_year_normal[('total_sales', 'std')]\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "\n",
        "axs[0].plot(game_releases_by_year_normal.index, mean_sales, label='Mean total_sales', color='blue')\n",
        "axs[0].fill_between(game_releases_by_year_normal.index, mean_sales - std_sales, mean_sales + std_sales, alpha=0.3, color='blue')\n",
        "axs[0].set_title('Mean total sales of a game per Year with Std Dev')\n",
        "axs[0].set_xlabel('Year')\n",
        "axs[0].set_ylabel('Sales (Millions)')\n",
        "axs[0].grid(True)\n",
        "axs[0].legend()\n",
        "\n",
        "\n",
        "# Right: Boxplot\n",
        "# Extract values from skewed summary DataFrame\n",
        "years = game_releases_by_year_skewed.index\n",
        "medians = game_releases_by_year_skewed[('total_sales', 'median')]\n",
        "q1 = game_releases_by_year_skewed[('total_sales', 'q1')]\n",
        "q3 = game_releases_by_year_skewed[('total_sales', 'q3')]\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Construct the boxplot-compatible stats manually\n",
        "# Construct the boxplot-compatible stats manually\n",
        "box_data = []\n",
        "for median, q_1, q_3, iqr_val in zip(medians, q1, q3, iqr):\n",
        "    # Compute \"whiskers\" (1.5 IQR rule)\n",
        "    lower_whisker = max(q_1 - 1.5 * iqr_val, 0)\n",
        "    upper_whisker = q_3 + 1.5 * iqr_val\n",
        "    box_data.append({\n",
        "        'med': median,\n",
        "        'q1': q_1,\n",
        "        'q3': q_3,\n",
        "        'whislo': lower_whisker,\n",
        "        'whishi': upper_whisker,\n",
        "        'fliers': []\n",
        "    })\n",
        "\n",
        "# Right: Custom boxplot from stats\n",
        "axs[1].bxp(box_data, positions=range(len(years)), showfliers=False, widths=0.6)\n",
        "axs[1].set_xticks(range(len(years)))\n",
        "axs[1].set_xticklabels([str(y) for y in years.year], rotation=45)\n",
        "axs[1].set_title('Boxplot of Total Sales per Year (Summary)')\n",
        "axs[1].set_xlabel('Year')\n",
        "axs[1].set_ylabel('Sales (Millions)')\n",
        "axs[1].set_position([0.55, 0.1, 0.4, 0.8])  # [left, bottom, width, height]\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate total sales by platform and year\n",
        "agg_dict = {\n",
        "    'name': 'count',\n",
        "    'platform': 'count',\n",
        "    'genre': 'count',\n",
        "    'na_sales': 'sum',\n",
        "    'eu_sales': 'sum',\n",
        "    'jp_sales': 'sum',\n",
        "    'other_sales': 'sum',\n",
        "    'critic_score': 'mean',\n",
        "    'user_score': 'mean',\n",
        "    'rating': 'count',\n",
        "    'total_sales': 'sum'\n",
        "}\n",
        "game_releases_by_platform_year = df.groupby(['platform','year_of_release']).agg(agg_dict)\n",
        "game_releases_by_platform_year.head()\n",
        "\n",
        "# Heatmap of platform sales over time\n",
        "# new df for heatmap\n",
        "heatmap_data = df.groupby(['platform', 'year_of_release'])['total_sales'].sum().reset_index()\n",
        "\n",
        "# Pivot for the heatmap\n",
        "heatmap_data = heatmap_data.pivot(\n",
        "    index='platform',\n",
        "    columns='year_of_release',\n",
        "    values='total_sales'\n",
        ")\n",
        "\n",
        "# the heatmap\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(heatmap_data, cmap='YlGnBu', interpolation='nearest')\n",
        "\n",
        "# color bar\n",
        "plt.colorbar()\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel(heatmap_data.index.name)\n",
        "plt.title('Heatmap of Total Sales by Platform and Year')\n",
        "\n",
        "# Set tick labels on the axes\n",
        "plt.xticks(\n",
        "    ticks=np.arange(len(heatmap_data.columns)),\n",
        "    labels=heatmap_data.columns.year,\n",
        "    rotation=45,\n",
        "    ha='right'\n",
        ")\n",
        "plt.yticks(\n",
        "    ticks=np.arange(len(heatmap_data.index)),\n",
        "    labels=heatmap_data.index\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# relevant years (3):\n",
        "relevant_years = list(range(2013, 2016))\n",
        "df_relevant = df[df['year_of_release'].dt.year.isin(relevant_years)]\n",
        "print(df_relevant.head())\n",
        "\n",
        "# platform sales trends\n",
        "sales_last_3_years = df_relevant.groupby(['platform', 'year_of_release'])['total_sales'].sum() #series\n",
        "print(df_relevant)\n",
        "\n",
        "# Sort platforms by total sales\n",
        "sales_last_3_years = sales_last_3_years.reset_index()\n",
        "platform_sales_last_3_years = sales_last_3_years.groupby('platform')['total_sales'].sum()\n",
        "platform_sales_last_3_years.sort_values( ascending = False)\n",
        "\n",
        "# Visualize top platforms\n",
        "platform_sales_last_3_years = platform_sales_last_3_years.reset_index()\n",
        "\n",
        "# Preparing heatmap data by setting 'platform' as the index\n",
        "heatmap_data = platform_sales_last_3_years.set_index('platform')[['total_sales']].sort_values(by='total_sales', ascending = False)\n",
        "\n",
        "# heatmap\n",
        "plt.figure(figsize=(15, 3))\n",
        "plt.imshow(heatmap_data, cmap='YlGnBu', interpolation='nearest')\n",
        "\n",
        "# color bar\n",
        "plt.colorbar()\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Platform')\n",
        "plt.title('Heatmap of Total Sales by Platform')\n",
        "\n",
        "\n",
        "plt.xticks(\n",
        "    ticks=np.arange(heatmap_data.shape[1]),\n",
        "    labels=heatmap_data.columns,\n",
        "    rotation=0,\n",
        "    ha='right'\n",
        ")\n",
        "\n",
        "plt.yticks(\n",
        "    ticks=np.arange(heatmap_data.shape[0]),\n",
        "    labels=heatmap_data.index\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# year-over-year growth for each platform\n",
        "sales_last_3_years['sales_growth'] = (sales_last_3_years['total_sales'] / sales_last_3_years.groupby('platform')['total_sales'].shift(1)) - 1\n",
        "sales_last_3_years['sales_growth'] = sales_last_3_years['sales_growth'].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "\n",
        "# year-over-year growth\n",
        "heatmap_data = sales_last_3_years.reset_index()\n",
        "heatmap_data = heatmap_data.pivot(\n",
        "    index='platform',\n",
        "    columns='year_of_release',\n",
        "    values='sales_growth'\n",
        ")\n",
        "\n",
        "# heatmap\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(heatmap_data, cmap='YlGnBu', interpolation='nearest')\n",
        "\n",
        "# color bar\n",
        "plt.colorbar()\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel(heatmap_data.index.name)\n",
        "plt.title('Heatmap of Sales Growth by Platform and Year')\n",
        "\n",
        "plt.xticks(\n",
        "    ticks=np.arange(len(heatmap_data.columns)),\n",
        "    labels=heatmap_data.columns.year,\n",
        "    rotation=45,\n",
        "    ha='right'\n",
        ")\n",
        "plt.yticks(\n",
        "    ticks=np.arange(len(heatmap_data.index)),\n",
        "    labels=heatmap_data.index\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# statistics for each platform\n",
        "print(sales_last_3_years.describe())\n",
        "print(sales_last_3_years.groupby('platform')['total_sales'].median())\n",
        "\n",
        "# scatter plots for both critic and user scores\n",
        "scatterplot_data = df_relevant[['critic_score','user_score']].dropna()\n",
        "plt.scatter(scatterplot_data['critic_score'], scatterplot_data['user_score'], alpha=0.5)\n",
        "plt.xlabel(df['critic_score'].name)\n",
        "plt.ylabel(df['user_score'].name)\n",
        "plt.title('Scatter Plot of Critic Score vs. User Score')\n",
        "plt.show()\n",
        "\n",
        "# Critic Scores\n",
        "view(df_relevant['critic_score'],'missing values')\n",
        "\n",
        "# User Scores\n",
        "view(df_relevant['user_score'],'missing values')\n",
        "\n",
        "# Calculate correlations\n",
        "scores_df = df_relevant[['critic_score','user_score']].dropna()\n",
        "\n",
        "rho, p_value = st.spearmanr(scores_df['critic_score'], scores_df['user_score'])\n",
        "print(f'correlation: {rho}\\np-value: {p_value}')\n",
        "\n",
        "# games released on multiple platforms\n",
        "last_3_years_df = df[df['year_of_release'].dt.year >= (df['year_of_release'].dt.year.max() - 9)]\n",
        "\n",
        "#the number of unique platforms for each name.\n",
        "name_by_platform = df_relevant.groupby(['name'])['platform'].nunique()\n",
        "\n",
        "# new series where platform unique > 1\n",
        "multi_platform_games = name_by_platform[name_by_platform > 1]\n",
        "\n",
        "# lists names on multiple platforms\n",
        "print(view(multi_platform_games,'summaries'))\n",
        "\n",
        "#multi_platform_games #series of names on multiple platforms\n",
        "multi_platform_games_list = multi_platform_games.index.to_list()\n",
        "\n",
        "# sales across platforms for these games\n",
        "# Group by 'name' and 'platform' then sum up total_sales\n",
        "name_platform_total_sales = df.groupby(['name', 'platform'])['total_sales'].sum()\n",
        "\n",
        "# Reset the index to convert the Series to a DataFrame\n",
        "name_platform_total_sales_reset_index = name_platform_total_sales.reset_index()\n",
        "\n",
        "# Apply filter for multi-platform games (ensure multi_platform_games is defined)\n",
        "name_multi_platform_total_sales = name_platform_total_sales_reset_index[\n",
        "    name_platform_total_sales_reset_index['name'].isin(multi_platform_games.index)\n",
        "]\n",
        "print(name_multi_platform_total_sales.shape[0])\n",
        "\n",
        "# compare_name_total_sales_by_platform\n",
        "compare_name_total_sales_x_platform = (\n",
        "    name_multi_platform_total_sales.pivot(\n",
        "        index = 'name',\n",
        "        columns = 'platform',\n",
        "        values = 'total_sales'\n",
        "    )\n",
        ")\n",
        "compare_name_total_sales_x_platform = compare_name_total_sales_x_platform.fillna(value = 0)\n",
        "print(compare_name_total_sales_x_platform.head())\n",
        "\n",
        "# genre performance\n",
        "genre = df_relevant.groupby('genre')['total_sales'].sum().sort_values(ascending = False)\n",
        "\n",
        "# Top 5 genres by total sales\n",
        "print(genre.head())\n",
        "\n",
        "# genre distribution\n",
        "plt.figure(figsize=(50, 10))\n",
        "genre.plot(\n",
        "    kind = 'bar',\n",
        "    ylabel = 'total_sales'\n",
        ")\n",
        "plt.xticks(\n",
        "    rotation = 0,\n",
        "    fontsize=30)\n",
        "plt.yticks(fontsize = 30)\n",
        "plt.ylabel('total_sales',fontsize = 30)\n",
        "plt.show()\n",
        "\n",
        "# market share for each genre\n",
        "market_size = genre.sum()\n",
        "genre_df = genre.to_frame()\n",
        "genre_df['percent'] = genre_df['total_sales']/market_size\n",
        "for genre_name, percent in zip(genre_df.index, genre_df['percent']):\n",
        "  print(genre_name, round(percent,2)*100,\"%\")\n",
        "\n",
        "# performance of the genre across time.\n",
        "year_genre = df_relevant.groupby(['genre', 'year_of_release'])['total_sales'].agg(['sum']) #.agg() keeps it as df.\n",
        "year_genre.reset_index(inplace = True)\n",
        "year_genre = year_genre.rename(columns={'year_of_release': 'year','sum':'total_sales'})\n",
        "year_genre['year'] = year_genre['year'].dt.strftime('%Y')\n",
        "year_genre = year_genre.pivot(\n",
        "    index='year',\n",
        "    columns = 'genre',\n",
        "    values = 'total_sales'\n",
        ")\n",
        "\n",
        "#average genre sales per year (row)\n",
        "year_genre['average_genre_sales_year'] = year_genre.mean(axis=1) #mean from column values\n",
        "\n",
        "#total sales of each genre across the years\n",
        "year_genre.loc['total_sales'] = year_genre.drop('average_genre_sales_year', axis=1).sum() #add row 'total Sales' by genre - excludes 'average_genre_sales_year' in calculation\n",
        "\n",
        "#average sales\n",
        "year_genre.loc['average_sales'] = year_genre.drop('total_sales', axis=0).mean(axis=0)\n",
        "\n",
        "# a year from two months ago\n",
        "see(year_genre[-12:-2])\n",
        "\n",
        "# Function to analyze platform performance by region\n",
        "def performance(platform, region):\n",
        "  #groupby row for col agg\n",
        "  agg_dict = {\n",
        "      'name' : 'count',\n",
        "      'platform' : 'count',\n",
        "      'year_of_release': 'count',\n",
        "      'genre' : 'count',\n",
        "      'na_sales':'sum',\n",
        "      'eu_sales':'sum',\n",
        "      'jp_sales':'sum',\n",
        "      'other_sales':'sum',\n",
        "      'critic_score':'sum',\n",
        "      'user_score':'sum',\n",
        "      'rating' : 'count',\n",
        "      'total_sales':'sum'\n",
        "  }\n",
        "\n",
        "  performance = df_relevant.groupby(['platform'])[region].agg(agg_dict[region])\n",
        "  print(f'{platform}:',performance.loc[platform])\n",
        "\n",
        "# performance of PS3\n",
        "performance('PS3','other_sales')\n",
        "\n",
        "# Analyze each region\n",
        "performance('PS3','na_sales')\n",
        "performance('PS3','eu_sales')\n",
        "performance('PS3','jp_sales')\n",
        "performance('PS3','other_sales')\n",
        "\n",
        "# comparative platform analysis\n",
        "agg_dict = {\n",
        "#    'name' : 'count',\n",
        "#    'platform' : 'count',\n",
        "#    'year_of_release': 'count',\n",
        "#    'genre' : 'count',\n",
        "    'na_sales':'sum',\n",
        "    'eu_sales':'sum',\n",
        "    'jp_sales':'sum',\n",
        "    'other_sales':'sum',\n",
        "#    'critic_score':'sum',\n",
        "#    'user_score':'sum',\n",
        "#    'rating' : 'count',\n",
        "#    'total_sales':'sum'\n",
        "}\n",
        "\n",
        "platform_sales = df_relevant.groupby(['platform'])[['na_sales','eu_sales','jp_sales','other_sales']].agg(agg_dict)\n",
        "print(platform_sales = df_relevant.groupby(['platform'])[['na_sales','eu_sales','jp_sales','other_sales']].agg(agg_dict)\n",
        ")\n",
        "\n",
        "# Visualize cross-regional comparison for top platforms\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(platform_sales, cmap='YlGnBu', interpolation='nearest')\n",
        "\n",
        "# color bar\n",
        "plt.colorbar()\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Platform')\n",
        "plt.ylabel(performance.index.name)\n",
        "plt.title('Heatmap of Platform Sales by Region')\n",
        "\n",
        "plt.xticks(\n",
        "    ticks=np.arange(len(performance.columns)),\n",
        "    labels=performance.columns,\n",
        "    rotation=45,\n",
        "    ha='right'\n",
        ")\n",
        "plt.yticks(\n",
        "    ticks=np.arange(len(performance.index)),\n",
        "    labels=performance.index\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# nalyze genre performance by region\n",
        "agg_dict = {\n",
        "#    'name' : 'count',\n",
        "#    'platform' : 'count',\n",
        "#    'year_of_release': 'count',\n",
        "#    'genre' : 'count',\n",
        "    'na_sales':'sum',\n",
        "    'eu_sales':'sum',\n",
        "    'jp_sales':'sum',\n",
        "    'other_sales':'sum',\n",
        "#    'critic_score':'sum',\n",
        "#    'user_score':'sum',\n",
        "#    'rating' : 'count',\n",
        "#    'total_sales':'sum'\n",
        "}\n",
        "\n",
        "genre_performance = df_relevant.groupby(['genre'])[['na_sales','eu_sales','jp_sales','other_sales']].agg(agg_dict)\n",
        "print(genre_performance)\n",
        "\n",
        "# heatmap\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(genre_performance, cmap='YlGnBu', interpolation='nearest')\n",
        "\n",
        "#  color bar\n",
        "plt.colorbar()\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Platform')\n",
        "plt.ylabel(genre_performance.index.name)\n",
        "plt.title('Heatmap of Platform Sales by Region')\n",
        "\n",
        "plt.xticks(\n",
        "    ticks=np.arange(len(genre_performance.columns)),\n",
        "    labels=genre_performance.columns,\n",
        "    rotation=45,\n",
        "    ha='right'\n",
        ")\n",
        "plt.yticks(\n",
        "    ticks=np.arange(len(genre_performance.index)),\n",
        "    labels=genre_performance.index\n",
        ")\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "# comparative genre analysis\n",
        "print(genre_performance)\n",
        "\n",
        "# ESRB rating impact\n",
        "agg_dict = {\n",
        "#    'name' : 'count',\n",
        "#    'platform' : 'count',\n",
        "#    'year_of_release': 'count',\n",
        "#    'genre' : 'count',\n",
        "    'na_sales':'sum',\n",
        "    'eu_sales':'sum',\n",
        "    'jp_sales':'sum',\n",
        "    'other_sales':'sum',\n",
        "#    'critic_score':'sum',\n",
        "#    'user_score':'sum',\n",
        "#    'rating' : 'count',\n",
        "#    'total_sales':'sum'\n",
        "}\n",
        "\n",
        "rating_performance = df_relevant.groupby(['rating'])[['na_sales','eu_sales','jp_sales','other_sales']].agg(agg_dict)\n",
        "print(rating_performance)\n",
        "\n",
        "# Analyze ESRB impact for each region\n",
        "print(rating_performance)\n",
        "\n",
        "#hypothesis testing\n",
        "# alpha = 0.05\n",
        "#—Average user ratings of the Xbox One and PC platforms are the same.\n",
        "xbox_one_query =\"platform == 'XOne'\"\n",
        "pc_query =  \"platform == 'PC'\"\n",
        "xbox_one_scores = df_relevant.query(xbox_one_query)['user_score']\n",
        "pc_scores = df_relevant.query(pc_query)['user_score']\n",
        "\n",
        "xbox_one_vs_pc_result = st.ttest_ind(xbox_one_scores, pc_scores, nan_policy='omit', equal_var=False)\n",
        "print(f'xbox_one_vs_pc_result p-value: {xbox_one_vs_pc_result.pvalue}\\n the mean scores are not the same - reject H0')\n",
        "\n",
        "\n",
        "#Average user ratings for the Action and Sports genres are the same.\n",
        "action_query = 'genre == \"Action\"'\n",
        "sports_query = 'genre == \"Sports\"'\n",
        "action_scores = df_relevant.query(action_query)['user_score']\n",
        "sports_scores = df_relevant.query(sports_query)['user_score']\n",
        "\n",
        "action_vs_sports_results = st.ttest_ind(action_scores, sports_scores, nan_policy='omit', equal_var=False)\n",
        "print(f'action_vs_sports_results p-value: {action_vs_sports_results.pvalue}\\n the mean scores are the same - accept H0')\n",
        "\n",
        "# general conclusion\n",
        "# peak game releases was 2008\n",
        "# peak sales was 2008\n",
        "# peak mean sales per game was 1989\n",
        "# new platform creates new sales, all platforms decline over time\n",
        "# sales cycle on a platform is about 10 years.\n",
        "# Top platforms by sales: PS3, X360, Wii\n",
        "# YoY growth is usually strongest in the first year and declines over time\n",
        "# Sales distributions by platform are not always normally distributed\n",
        "# critic score and user score are correlated\n",
        "# The top selling genre is Action\n",
        "# Sales across all genres are declining\n",
        "# NA followed by the EU do the most sales\n",
        "# Na AND EU perform similarly\n",
        "# jp and other perform similarly\n",
        "# Genre sales vary by region\n",
        "# ratings vary by region sales\n",
        "# ratings appear associated with sales (higher rations, higher sales)\n",
        "# Average user ratings are different for xbox and PC\n",
        "# average user rations are not different for action vs Sports genre\n",
        "# we could do a much better analysis if we had price and units sold.\n"
      ]
    }
  ]
}