{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcEhGvo6lqb2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Marketing needs to predict who's likely to be a custom, receive benefits, how many benefits, while protecting their data.\n",
        "'''\n",
        "\n",
        "# libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import seaborn as sns\n",
        "import sklearn.linear_model\n",
        "import sklearn.metrics\n",
        "import sklearn.neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import sklearn.preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display\n",
        "\n",
        "# load data\n",
        "df = pd.read_csv('/datasets/insurance_us.csv')\n",
        "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})\n",
        "df.sample(10)\n",
        "df.info()\n",
        "df.describe()\n",
        "\n",
        "## EDA\n",
        "g = sns.pairplot(df, kind='hist')\n",
        "g.figure.set_size_inches(12, 12)\n",
        "\n",
        "# define features\n",
        "feature_names = ['gender', 'age', 'income', 'family_members']\n",
        "features = feature_names\n",
        "\n",
        "## scale features\n",
        "# get max abs vals of features array\n",
        "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
        "\n",
        "# make copy of df\n",
        "df_scaled = df.copy()\n",
        "\n",
        "# apply scaler to features of copy df\n",
        "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())\n",
        "\n",
        "## finding similar records to a random sample of 5 customers\n",
        "for idx in df_scaled.sample(5).index:\n",
        "    print(\"Unscaled - Euclidean\")\n",
        "    display(get_knn(df, row=idx, k=5, metric=2))\n",
        "\n",
        "    print(\"Unscaled - Manhattan\")\n",
        "    display(get_knn(df, row=idx, k=5, metric=1))\n",
        "\n",
        "    print(\"Scaled - Euclidean\")\n",
        "    display(get_knn(df_scaled, row=idx, k=5, metric=2))\n",
        "\n",
        "    print(\"Scaled - Manhattan\")\n",
        "    display(get_knn(df_scaled, row=idx, k=5, metric=1))\n",
        "\n",
        "## likely to receive benefits\n",
        "# convert continous number of benefits to binary\n",
        "df['insurance_benefits_received'] = (df['insurance_benefits'] > 0).astype(int)\n",
        "target = 'insurance_benefits_received'\n",
        "\n",
        "# check for the class imbalance with value_counts()\n",
        "(df['insurance_benefits_received']).value_counts()\n",
        "\n",
        "# function to eval classifier using f1\n",
        "def eval_classifier(y_true, y_pred):\n",
        "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
        "    print(f'F1: {f1_score:.2f}')\n",
        "\n",
        "\n",
        "# generating random binary outcomes\n",
        "def rnd_model_predict(P, size, seed=42):\n",
        "    rng = np.random.default_rng(seed=seed)\n",
        "    return rng.binomial(n=1, p=P, size=size)\n",
        "\n",
        "# dummy outcomes (0, mean, .5, 1) and their corresponding f1 and confusion matrix\n",
        "for P in [0, df[target].sum() / len(df), 0.5, 1]:\n",
        "    print(f'The probability: {P:.2f}')\n",
        "    y_pred_rnd =  rnd_model_predict(P=P, size=len(df))\n",
        "    eval_classifier(df[target], y_pred_rnd)\n",
        "    print()\n",
        "\n",
        "## scale features then test knn scaled vs unscaled\n",
        "# split data:\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.3, random_state=12345)\n",
        "\n",
        "# align indices\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "\n",
        "# scale features:\n",
        "# train:\n",
        "\n",
        "# fit scaler to vectorized features and get max abs vals.\n",
        "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(X_train[features].to_numpy())\n",
        "\n",
        "# copy df to not affect original df\n",
        "X_train_scaled = X_train.copy()\n",
        "\n",
        "# copy df to not affect original df\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "# apply scaler and save in copied df.\n",
        "X_train_scaled.loc[:, features] = transformer_mas.transform(X_train[features].to_numpy())\n",
        "\n",
        "# apply scaler and save in copied df.\n",
        "X_test_scaled.loc[:, features] = transformer_mas.transform(X_test[features].to_numpy())\n",
        "\n",
        "# test knn unscaled vs scaled\n",
        "for k in range(1,11):\n",
        "    # unscaled\n",
        "    #print(f'not scaled:')\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred_unscaled = knn.predict(X_test)\n",
        "    # eval_classifier(y_test, y_pred_unscaled)\n",
        "    print(f'k:{k}')\n",
        "\n",
        "    #scaled\n",
        "    #print(f'scaled:')\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "    y_pred_scaled = knn.predict(X_test_scaled)\n",
        "\n",
        "    eval_classifier(y_test, y_pred_unscaled)\n",
        "    eval_classifier(y_test, y_pred_scaled)\n",
        "    #print(f'k:{k}')\n",
        "\n",
        "# results\n",
        "# k=2\n",
        "# F1: 0.64\n",
        "# Confusion Matrix\n",
        "# [[0.866      0.01942857]\n",
        "#  [0.05085714 0.06371429]]\n",
        "# F1: 0.94\n",
        "# Confusion Matrix\n",
        "# [[0.88171429 0.00371429]\n",
        "#  [0.00885714 0.10571429]]\n",
        "\n",
        "# k=3\n",
        "# F1: 0.39\n",
        "# Confusion Matrix\n",
        "# [[0.88257143 0.00285714]\n",
        "#  [0.08571429 0.02885714]]\n",
        "# F1: 0.91\n",
        "# Confusion Matrix\n",
        "# [[0.884      0.00142857]\n",
        "#  [0.01857143 0.096     ]]\n",
        "\n",
        "# k=4\n",
        "# F1: 0.41\n",
        "# Confusion Matrix\n",
        "# [[0.87285714 0.01257143]\n",
        "#  [0.082      0.03257143]]\n",
        "# F1: 0.93\n",
        "# Confusion Matrix\n",
        "# [[0.88171429 0.00371429]\n",
        "#  [0.01142857 0.10314286]]\n",
        "\n",
        "# k=5\n",
        "# F1: 0.19\n",
        "# Confusion Matrix\n",
        "# [[0.88228571 0.00314286]\n",
        "#  [0.10257143 0.012     ]]\n",
        "# F1: 0.91\n",
        "# Confusion Matrix\n",
        "# [[0.88371429 0.00171429]\n",
        "#  [0.01828571 0.09628571]]\n",
        "\n",
        "# k=6\n",
        "# F1: 0.19\n",
        "# Confusion Matrix\n",
        "# [[0.88       0.00542857]\n",
        "#  [0.10171429 0.01285714]]\n",
        "# F1: 0.93\n",
        "# Confusion Matrix\n",
        "# [[0.88257143 0.00285714]\n",
        "#  [0.01314286 0.10142857]]\n",
        "\n",
        "# k=7\n",
        "# F1: 0.06\n",
        "# Confusion Matrix\n",
        "# [[0.88428571 0.00114286]\n",
        "#  [0.11114286 0.00342857]]\n",
        "# F1: 0.90\n",
        "# Confusion Matrix\n",
        "# [[0.88428571 0.00114286]\n",
        "#  [0.01971429 0.09485714]]\n",
        "\n",
        "# k=8\n",
        "# F1: 0.07\n",
        "# Confusion Matrix\n",
        "# [[0.88314286 0.00228571]\n",
        "#  [0.11057143 0.004     ]]\n",
        "# F1: 0.93\n",
        "# Confusion Matrix\n",
        "# [[0.88371429 0.00171429]\n",
        "#  [0.01371429 0.10085714]]\n",
        "\n",
        "# k=9\n",
        "# F1: 0.00\n",
        "# Confusion Matrix\n",
        "# [[0.88542857 0.        ]\n",
        "#  [0.11457143 0.        ]]\n",
        "# F1: 0.90\n",
        "# Confusion Matrix\n",
        "# [[0.88428571 0.00114286]\n",
        "#  [0.01971429 0.09485714]]\n",
        "\n",
        "# k=10\n",
        "# F1: 0.00\n",
        "# Confusion Matrix\n",
        "# [[8.85142857e-01 2.85714286e-04]\n",
        "#  [1.14285714e-01 2.85714286e-04]]\n",
        "# F1: 0.93\n",
        "# Confusion Matrix\n",
        "# [[0.88314286 0.00228571]\n",
        "#  [0.01371429 0.10085714]]\n",
        "\n",
        "## predict number of benefits scaled vs unscaled\n",
        "# make model\n",
        "class MyLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # adding constant\n",
        "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
        "\n",
        "        # calculating weights\n",
        "        self.weights = np.linalg.inv(X2.T @ X2) @ X2.T @ y\n",
        "\n",
        "    def predict(self, X):\n",
        "        # adding constant\n",
        "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
        "\n",
        "        # predicting y\n",
        "        y_pred = X2 @ self.weights\n",
        "        return y_pred\n",
        "\n",
        "def eval_regressor(y_true, y_pred):\n",
        "    # calculating RMSE\n",
        "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
        "    print(f'RMSE: {rmse:.2f}')\n",
        "\n",
        "    # calculating r2\n",
        "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
        "    print(f'R2: {r2_score:.2f}')\n",
        "\n",
        "# prepare data\n",
        "# redefine target\n",
        "target = 'insurance_benefits'\n",
        "\n",
        "# split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.3, random_state=12345)\n",
        "\n",
        "# scale features\n",
        "# fit scaler to vectorized features and get max abs vals.\n",
        "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(X_train[features].to_numpy())\n",
        "\n",
        "# copy df to not affect original df\n",
        "X_train_scaled = X_train.copy()\n",
        "\n",
        "# copy df to not affect original df\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "# apply scaler and save in copied df.\n",
        "X_train_scaled.loc[:, features] = transformer_mas.transform(X_train[features].to_numpy())\n",
        "\n",
        "# apply scaler and save in copied df.\n",
        "X_test_scaled.loc[:, features] = transformer_mas.transform(X_test[features].to_numpy())\n",
        "\n",
        "# Apply linear regression\n",
        "# initialize class\n",
        "lr = MyLinearRegression()\n",
        "\n",
        "# not scaled:\n",
        "# fit model\n",
        "lr.fit(X_train, y_train)\n",
        "print(lr.weights)\n",
        "\n",
        "# predict\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "# evaluate\n",
        "eval_regressor(y_test, y_test_pred)\n",
        "\n",
        "#scaled\n",
        "# fit model\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "print(lr.weights)\n",
        "\n",
        "# predict\n",
        "y_test_pred = lr.predict(X_test_scaled)\n",
        "\n",
        "# evaluate\n",
        "eval_regressor(y_test, y_test_pred)\n",
        "\n",
        "'''\n",
        "same results between scaled and unscaled data.\n",
        "'''\n",
        "\n",
        "## obfuscating data\n",
        "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
        "df_pn = df[personal_info_column_list]\n",
        "\n",
        "# vectorize\n",
        "X = df_pn.to_numpy()\n",
        "\n",
        "# generate random matrix P with seed\n",
        "rng = np.random.default_rng(seed=42)\n",
        "P = rng.random(size=(X.shape[1], X.shape[1]))\n",
        "\n",
        "#checking invertibility\n",
        "det_P = np.linalg.det(P)\n",
        "print(\"Determinant of P:\", det_P)\n",
        "\n",
        "# x_ transformed = XP, obfuscate data\n",
        "X_transformed = X @ P\n",
        "print(X_transformed)\n",
        "\n",
        "# recover obfuscated data\n",
        "# X = x_ transformed / P\n",
        "X_recovered = X_transformed @ np.linalg.inv(P)\n",
        "\n",
        "# 3 tests\n",
        "for i in range(3):\n",
        "    print(f\"\\nCustomer {i+1}:\")\n",
        "    print(\"Original:   \", X[i])\n",
        "    print(\"Transformed:\", X_transformed[i])\n",
        "    print(\"Recovered:  \", X_recovered[i])\n",
        "\n",
        "# testing linear regression with obfuscated data\n",
        "# set X and P\n",
        "X = df[features]\n",
        "rng = np.random.default_rng(seed=42)\n",
        "P = rng.random(size=(X.shape[1], X.shape[1]))\n",
        "\n",
        "# ensure P is invertible.\n",
        "det_P = 0\n",
        "while det_P != 0:\n",
        "    P = rng.random(size=(X.shape[1], X.shape[1]))\n",
        "    det_P = np.linalg.det(P)\n",
        "\n",
        "# Use XP as the new feature matrix\n",
        "X_obfuscated = X_train @ P\n",
        "X_test_obfuscated = X_test @ P\n",
        "\n",
        "## lr for obfuscated\n",
        "# fit model\n",
        "lr.fit(X_obfuscated, y_train)\n",
        "print(lr.weights)\n",
        "\n",
        "# predict\n",
        "y_test_pred = lr.predict(X_test_obfuscated)\n",
        "\n",
        "# evaluate\n",
        "eval_regressor(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "## lr for original data\n",
        "# fit model\n",
        "lr.fit(X_train, y_train)\n",
        "print(lr.weights)\n",
        "\n",
        "# predict\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "# evaluate\n",
        "eval_regressor(y_test, y_test_pred)\n",
        "\n",
        "'''\n",
        "technical conclusions:\n",
        "Scale features before using KNN classifier. Scaling features has no effect on linear regression.\n",
        "Apply any invertible matrix,P, to obfuscate data, but save P!\n",
        "'''"
      ]
    }
  ]
}