{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZmL0mDgExNZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Business case: Client wants to offer their customers an automated estiamte of what their car could sell for.\n",
        "Project: Predict 'Price'.\n",
        "'''\n",
        "\n",
        "# libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "# load data\n",
        "df = pd.read_csv('car_data.csv')\n",
        "df = df.sample(10000, random_state = 12345)\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "\n",
        "## EDA\n",
        "# track ordinal and categorical cols.\n",
        "ordinal = []\n",
        "categorical = []\n",
        "\n",
        "# col 0\n",
        "column = 0\n",
        "print(df.columns[column]) # 'DateCrawled'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: int64\n",
        "print(df.iloc[:,column].head())\n",
        "#sns.histplot(df.iloc[:,column], bins=30, kde=False)\n",
        "#plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {354369 - len(df.iloc[:,column])}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numberical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "df = df.drop(df.columns[column],axis = 1)\n",
        "# Feature engineering\n",
        "\n",
        "\n",
        "# QC\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# EDA\n",
        "# new col 0:\n",
        "column = 0\n",
        "print(df.columns[column]) # 'Price'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) #dtype: int64\n",
        "print(df.iloc[:,column].head())\n",
        "df.iloc[:, column].plot(kind='hist', bins=20)\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'n 0s: {(df.iloc[:,column] == 0).sum()}, {(df.iloc[:,column] == 0).sum()/(df.iloc[:,column]).count()}')\n",
        "print(f'missing: {354369 - len(df.iloc[:,column])}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numberical\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "df.iloc[:,column] = np.where((df.iloc[:,column] >= 500), df.iloc[:,column], np.nan)\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'n 0s: {(df.iloc[:,column] == 0).sum()}, {(df.iloc[:,column] == 0).sum()/(df.iloc[:,column]).count()}')\n",
        "print(df.iloc[:,column].describe())\n",
        "\n",
        "\n",
        "# observations\n",
        "# missing might be set at zero.  Otherwise, no odd values.  No designated missing values.\n",
        "\n",
        "# EDA\n",
        "# col 1\n",
        "column = 1\n",
        "print(df.columns[column]) # 'VehicleType'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: object (text)\n",
        "print(df.iloc[:,column].head())\n",
        "df.iloc[:,column].value_counts().head(30).plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "categorical.append(df.columns[column])\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "df.iloc[:,column] = df.iloc[:,column].fillna('missing')\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "# observations\n",
        "# missing values saved as 'missing' to include the row of data.\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 2\n",
        "column = 2\n",
        "print(df.columns[column]) # 'RegistrationYear'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: int64\n",
        "print(df.iloc[:,column].head())\n",
        "df.iloc[:, column].plot(kind='hist', bins=30)\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "df.iloc[:,column] = df.iloc[:,column].where((df.iloc[:,column] >= 1900) & (df.iloc[:,column] <= 2025))\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "df.iloc[:,column] = df.iloc[:,column].fillna(0) # this keeps the row, but 0 should clearly be understood as missing\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "\n",
        "# observations\n",
        "# No missing, but certainly odd values. I turned all values outside of the range 1900-2025 to 0.  I didn't want to leave as NaN to lose the row.  I can't label it as 'missing' or it would change the dtype.  Not sure what a better solution is.\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 3\n",
        "column = 3\n",
        "print(df.columns[column]) # 'Gearbox'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: object\n",
        "print(df.iloc[:,column].head())\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "categorical.append(df.columns[column])\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "df.iloc[:,column] = df.iloc[:,column].fillna('missing')\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "\n",
        "# observations\n",
        "# missing saved as 'missing' to keep the row.\n",
        "\n",
        "# EDA\n",
        "# col 4\n",
        "column = 4\n",
        "# print(df.columns[column]) # 'Power'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: int64\n",
        "# print(np.sort(df.iloc[:,column].unique()))\n",
        "\n",
        "df.iloc[:, column].plot(kind='hist', bins=20)\n",
        "plt.show()\n",
        "\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "df.iloc[:,column] = df.iloc[:,column].where((df.iloc[:,column] >= 100) & (df.iloc[:,column] <= 400))\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# df.iloc[:,column] = df.iloc[:,column].fillna(0) # this keeps the row, but 0 should clearly be understood as missing\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(df.iloc[:,column].describe())\n",
        "df.iloc[:, column].plot(kind='hist', bins=20)\n",
        "plt.show()\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# observations\n",
        "# There is no missing, but these values don't make sense to me. I set all values outside of 100-400 to zero.\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 5\n",
        "column = 5\n",
        "print(df.columns[column]) # 'Model'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: object\n",
        "print((df.iloc[:,column].value_counts().sort_values(ascending = False)))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "categorical.append(df.columns[column])\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "df.iloc[:,column] = df.iloc[:,column].fillna('missing')\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 6\n",
        "column = 6\n",
        "print(df.columns[column]) # 'Mileage'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype)\n",
        "#dtype: int64\n",
        "print(np.sort(df.iloc[:,column].unique()))\n",
        "df.iloc[:, column].plot(kind='hist', bins=20)\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 7\n",
        "column = 7\n",
        "print(df.columns[column]) # 'RegistrationMonth'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # int64\n",
        "print(np.sort(df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.loc[df.iloc[:, column] == 0,df.columns[column]].count()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "df.iloc[:, column] = df.iloc[:, column].replace(0, np.nan)\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "df = df.drop(df.columns[column],axis = 1)\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "# there are 13 options for registration month, I assume 0 = missing and will drop it in the end.\n",
        "# I ended up dropping the column because I don't see how this could correlate to Price.\n",
        "\n",
        "\n",
        "# EDA\n",
        "# new col 7\n",
        "column = 7\n",
        "print(df.columns[column]) # 'FuelType'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # object\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "categorical.append(df.columns[column])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "df.iloc[:, column] = df.iloc[:, column].replace(np.nan, 'missing')\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 8\n",
        "column = 8\n",
        "print(df.columns[column]) # 'Brand'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # object\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "categorical.append(df.columns[column])\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 9\n",
        "column = 9\n",
        "print(df.columns[column]) # 'NotRepaired'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # object\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "categorical.append(df.columns[column])\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "df.iloc[:, column] = df.iloc[:, column].fillna('missing')\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# EDA\n",
        "# col 10\n",
        "column = 10\n",
        "print(df.columns[column]) # 'DateCreated'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # object\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "df.drop('DateCreated', axis=1, inplace=True)\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(\"Deleted\" if 'DateCreated' not in df.columns else \"Not deleted\")\n",
        "\n",
        "\n",
        "\n",
        "# EDA\n",
        "# new col 10\n",
        "column = 10\n",
        "print(df.columns[column]) # 'NumberOfPictures'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # int64\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "df.drop('NumberOfPictures', axis=1, inplace=True)\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(\"Deleted\" if 'NumberOfPictures' not in df.columns else \"Not deleted\")\n",
        "\n",
        "\n",
        "# EDA\n",
        "# new col 10\n",
        "column = 10\n",
        "print(df.columns[column]) # 'PostalCode'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # object\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# categorical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# df.iloc[:, column] = df.iloc[:, column].astype(str)\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns - too many unique values\n",
        "df.drop('PostalCode', axis=1, inplace=True)\n",
        "\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "print(\"Deleted\" if 'PostalCode' not in df.columns else \"Not deleted\")\n",
        "\n",
        "\n",
        "# EDA\n",
        "# new col 10\n",
        "column = 10\n",
        "print(df.columns[column]) # 'LastSeen'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # object\n",
        "print((df.iloc[:,column].unique()))\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "df.iloc[:, column] = pd.to_datetime(df.iloc[:, column], errors='coerce')\n",
        "# Remove missing data\n",
        "# Feature engineering\n",
        "df[f'LastSeen_month'] = df[f'LastSeen'].dt.month\n",
        "df[f'LastSeen_day'] = df[f'LastSeen'].dt.day\n",
        "# Remove irrelevant columns\n",
        "df.drop('LastSeen', axis=1, inplace=True)\n",
        "\n",
        "# drop\n",
        "print(\"Deleted\" if 'LastSeen' not in df.columns else \"Not deleted\")\n",
        "\n",
        "# QC\n",
        "print(df.iloc[:,column].dtype)\n",
        "print(df[f'LastSeen_month'].head())\n",
        "print(df[f'LastSeen_day'].head())\n",
        "\n",
        "# EDA\n",
        "# new col 10\n",
        "column = 10\n",
        "print(df.columns[column]) # 'LastSeen_month'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # int64\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "df = df.drop(df.columns[column],axis = 1)\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "# decided to remove.\n",
        "\n",
        "# EDA\n",
        "# new col 10\n",
        "column = 10\n",
        "print(df.columns[column]) # 'LastSeen_day'\n",
        "\n",
        "# understand values:\n",
        "print(df.iloc[:,column].dtype) # int64\n",
        "print((df.iloc[:,column].unique()))\n",
        "df.iloc[:,column].value_counts().plot(kind='bar')\n",
        "plt.show()\n",
        "print(df.iloc[:,column].describe())\n",
        "print(f'missing: {df.iloc[:, column].isnull().sum()}')\n",
        "# how I will treat the col for encoding (numerical, ordinal, categorical):\n",
        "# numerical\n",
        "\n",
        "# changes:\n",
        "# Edit values\n",
        "# Update data types\n",
        "# Remove missing data\n",
        "# Remove irrelevant columns\n",
        "df = df.drop(df.columns[column],axis = 1)\n",
        "# Feature engineering\n",
        "\n",
        "# QC\n",
        "# decided not to keep\n",
        "\n",
        "# row clean up\n",
        "# drop duplicates in the end\n",
        "df.drop_duplicates(inplace = True)\n",
        "\n",
        "#dropna\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "# move target to be first column\n",
        "target = 'Price'\n",
        "df = df[ [target] + [col for col in df.columns if col != target]]\n",
        "\n",
        "\n",
        "## prepare for vectorization\n",
        "# Split data\n",
        "random_state = 12345\n",
        "train_ratio = .6\n",
        "valid_ratio = .2\n",
        "test_ratio = .2\n",
        "# data.split(split_ratio=(0.6, 0.2, 0.2), target_name=target_name, random_state=random_state).vectorize()\n",
        "\n",
        "# First split: separate out the test set.\n",
        "df_temp, df_test = train_test_split(df, test_size=test_ratio, random_state=random_state)\n",
        "\n",
        "# Recalculate validation ratio relative to the remaining data (df_temp).\n",
        "valid_ratio = valid_ratio / (1 - test_ratio)\n",
        "\n",
        "df_train, df_valid = train_test_split(df_temp, test_size=valid_ratio, random_state=random_state)\n",
        "\n",
        "# encode data - regression\n",
        "# 'Regressions':\n",
        "# -- One-hot encodes categorical_cols.\n",
        "# -- Ordinal  encoding for ordinal cols.\n",
        "# 'Machine Learning':\n",
        "# -- Ordinal encodes for both ordinal cols and categorical cols.\n",
        "\n",
        "# Regression model data\n",
        "df_train_regressions = df_train.copy()\n",
        "df_valid_regressions = df_valid.copy()\n",
        "df_test_regressions = df_test.copy()\n",
        "\n",
        "\n",
        "# initialize OHE\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False) # did not drop='first' because valid/train has other categories.\n",
        "\n",
        "# generate OHE array\n",
        "train_encoded = ohe.fit_transform(df_train[categorical])\n",
        "\n",
        "# Get OHE array feature names to make df\n",
        "ohe_cols = ohe.get_feature_names(categorical)\n",
        "\n",
        "# convert OHE array to df using feature names\n",
        "train_encoded_df = pd.DataFrame(train_encoded, columns=ohe_cols, index=df_train.index)\n",
        "\n",
        "# drop old df_train feature cols and add new OHE array\n",
        "df_train_regressions = pd.concat([df_train.drop(columns=categorical), train_encoded_df], axis=1)\n",
        "\n",
        "\n",
        "# apply array to valid and test and update respective dfs\n",
        "# valid\n",
        "valid_encoded = ohe.transform(df_valid[categorical])\n",
        "valid_encoded_df = pd.DataFrame(valid_encoded, columns=ohe_cols, index=df_valid.index)\n",
        "df_valid_regressions = pd.concat([df_valid.drop(columns=categorical), valid_encoded_df], axis=1)\n",
        "\n",
        "# test\n",
        "test_encoded = ohe.transform(df_test[categorical])\n",
        "test_encoded_df  = pd.DataFrame(test_encoded,  columns=ohe_cols, index=df_test.index)\n",
        "df_test_regressions  = pd.concat([df_test.drop(columns=categorical),  test_encoded_df],  axis=1)\n",
        "\n",
        "# QC\n",
        "print(f'{df_train_regressions.columns},\\n {df_valid_regressions.columns},\\n {df_test_regressions.columns}')\n",
        "\n",
        "#Encode data - ML\n",
        "# ML model data\n",
        "df_train_ML = df_train.copy()\n",
        "df_valid_ML = df_valid.copy()\n",
        "df_test_ML = df_test.copy()\n",
        "dfs = [df_train_ML, df_valid_ML, df_test_ML]\n",
        "\n",
        "# label encode\n",
        "text_values_dict = {'ordinal': {}, 'categorical': {}}\n",
        "\n",
        "for each_df in dfs:\n",
        "    for each_col in categorical:\n",
        "\n",
        "        # get unique values\n",
        "        unique_values = sorted(each_df[each_col].dropna().unique())\n",
        "\n",
        "        # make a dictionary of category: value\n",
        "        mapping_dict = {val: idx for idx, val in enumerate(unique_values)}\n",
        "\n",
        "        # Replace col val with idx\n",
        "        each_df[each_col] = each_df[each_col].map(mapping_dict)\n",
        "\n",
        "        # Save dict to text_values_dict tracker\n",
        "        text_values_dict['categorical'][each_col] = mapping_dict\n",
        "\n",
        "# QC\n",
        "print(df_train_ML.shape, df_valid_ML.shape, df_test_ML.shape)\n",
        "\n",
        "# scale features\n",
        "\n",
        "# duplicate df\n",
        "# regression\n",
        "df_train_regressions_scaled = df_train_regressions.copy()\n",
        "df_valid_regressions_scaled = df_valid_regressions.copy()\n",
        "df_test_regressions_scaled = df_test_regressions.copy()\n",
        "\n",
        "# ML\n",
        "df_train_ML_scaled = df_train_ML.copy()\n",
        "df_valid_ML_scaled = df_valid_ML.copy()\n",
        "df_test_ML_scaled = df_test_ML.copy()\n",
        "\n",
        "# initialize scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# define feature and target\n",
        "# regression\n",
        "target_name_reg = df_train_regressions_scaled.columns[0]\n",
        "features_name_reg = df_train_regressions_scaled.columns[1:]\n",
        "\n",
        "# scale train features - regression\n",
        "features_train_regressions_scaled = scaler.fit_transform(df_train_regressions_scaled[features_name_reg])\n",
        "\n",
        "# apply same scaler to valid and test features\n",
        "feature_valid_regressions_scaled = scaler.transform(df_valid_regressions_scaled[features_name_reg])\n",
        "feature_test_regressions_scaled = scaler.transform(df_test_regressions_scaled[features_name_reg])\n",
        "\n",
        "# ML\n",
        "\n",
        "# define feature and target\n",
        "# ML\n",
        "target_name_ML = df_train_ML_scaled.columns[0]\n",
        "features_name_ML = df_train_ML_scaled.columns[1:]\n",
        "\n",
        "# scale train features - ML\n",
        "feature_train_ML_scaled = scaler.fit_transform(df_train_ML_scaled[features_name_ML])\n",
        "\n",
        "# apply scaler to valid and test features\n",
        "feature_valid_ML_scaled = scaler.transform(df_valid_ML_scaled[features_name_ML])\n",
        "feature_test_ML_scaled = scaler.transform(df_test_ML_scaled[features_name_ML])\n",
        "\n",
        "# vectorize y (x already vectorized via scaling)\n",
        "# regression\n",
        "target_train_reg_vectorized = df_train_regressions_scaled['Price'].to_numpy()\n",
        "target_valid_reg_vectorized = df_valid_regressions_scaled['Price'].to_numpy()\n",
        "target_test_reg_vectorized = df_test_regressions_scaled['Price'].to_numpy()\n",
        "\n",
        "# ML\n",
        "target_train_ML_vectorized = df_train_ML_scaled['Price'].to_numpy()\n",
        "target_valid_ML_vectorized = df_valid_ML_scaled['Price'].to_numpy()\n",
        "target_test_ML_vectorized = df_test_ML_scaled['Price'].to_numpy()\n",
        "\n",
        "# Model training\n",
        "# tracking time to fit and predict all models\n",
        "\n",
        "# linear regression\n",
        "# initialize model\n",
        "lr_model = LinearRegression()\n",
        "\n",
        "# fit model\n",
        "start_time = time.time()\n",
        "lr_model.fit(features_train_regressions_scaled,target_train_reg_vectorized )\n",
        "end_time = time.time()\n",
        "lr_train_time = end_time - start_time\n",
        "print(f'train time: {lr_train_time}')\n",
        "\n",
        "# pred target\n",
        "start_time = time.time()\n",
        "target_valid_pred = lr_model.predict(features_train_regressions_scaled)\n",
        "end_time = time.time()\n",
        "lr_pred_time = end_time - start_time\n",
        "print(f'pred time: {lr_pred_time}')\n",
        "\n",
        "# rmse score with reverse scaling\n",
        "target_valid_std_dev = np.std(df_valid_regressions['Price'])\n",
        "linear_rmse = np.sqrt(mean_squared_error(target_train_reg_vectorized, target_valid_pred))\n",
        "print(f'rmse: {linear_rmse}') # 2478.693608591162\n",
        "\n",
        "# observations\n",
        "# rmse is high.\n",
        "\n",
        "# fit lgbm\n",
        "# initialize model\n",
        "lgb_model = lgb.LGBMRegressor()\n",
        "\n",
        "# fit\n",
        "start_time = time.time()\n",
        "lgb_model.fit(feature_train_ML_scaled, target_train_ML_vectorized)\n",
        "end_time = time.time()\n",
        "lgb_train_time = end_time - start_time\n",
        "print(f'train time: {lgb_train_time}')\n",
        "\n",
        "# predict\n",
        "start_time = time.time()\n",
        "target_valid_ML_pred = lgb_model.predict(feature_valid_ML_scaled)\n",
        "end_time = time.time()\n",
        "lgb_pred_time = end_time - start_time\n",
        "print(f'pred time: {lgb_pred_time}')\n",
        "\n",
        "# score\n",
        "lgb_rmse = np.sqrt(mean_squared_error(target_valid_ML_vectorized, target_valid_ML_pred))\n",
        "print(f'rmse: {lgb_rmse}') # 2628.9684481111476\n",
        "\n",
        "# observation\n",
        "# rmse is higher than linear regression\n",
        "\n",
        "# fit RandomForestClassifier\n",
        "# initialize model\n",
        "rfr_model = RandomForestRegressor()\n",
        "\n",
        "# fit\n",
        "start_time = time.time()\n",
        "rfr_model.fit(feature_train_ML_scaled, target_train_ML_vectorized)\n",
        "end_time = time.time()\n",
        "rfr_train_time = end_time - start_time\n",
        "print(f'train time: {rfr_train_time}')\n",
        "\n",
        "# predict\n",
        "start_time = time.time()\n",
        "target_valid_ML_pred = rfr_model.predict(feature_valid_ML_scaled)\n",
        "end_time = time.time()\n",
        "rfr_pred_time = end_time - start_time\n",
        "print(f'pred time: {rfr_pred_time}')\n",
        "\n",
        "# score\n",
        "rfr_rmse = np.sqrt(mean_squared_error(target_valid_ML_vectorized, target_valid_ML_pred))\n",
        "print(f'rmse: {rfr_rmse}') # 2868.6650270179457\n",
        "\n",
        "# observation\n",
        "# rmse is higher than lgb\n",
        "\n",
        "# fit catboost\n",
        "# initialize model\n",
        "cat_model = cb.CatBoostRegressor()\n",
        "\n",
        "# fit\n",
        "start_time = time.time()\n",
        "cat_model.fit(feature_train_ML_scaled, target_train_ML_vectorized)\n",
        "end_time = time.time()\n",
        "cat_train_time = end_time - start_time\n",
        "print(f'train time: {cat_train_time}')\n",
        "\n",
        "# predict\n",
        "start_time = time.time()\n",
        "target_valid_ML_pred = cat_model.predict(feature_valid_ML_scaled)\n",
        "end_time = time.time()\n",
        "cat_pred_time = end_time - start_time\n",
        "print(f'pred time: {cat_pred_time}')\n",
        "\n",
        "# score\n",
        "cat_rmse = np.sqrt(mean_squared_error(target_valid_ML_vectorized, target_valid_ML_pred))\n",
        "print(f'rmse: {cat_rmse}') # 2657.1477314704466\n",
        "\n",
        "# observation\n",
        "# rmse is higher than linear\n",
        "\n",
        "# model parameter optimization\n",
        "for value in range(2,6):\n",
        "    param_values =  value\n",
        "    param = {'max_depth': param_values, 'verbose': 0}\n",
        "\n",
        "    cat_model = cb.CatBoostRegressor(**param)\n",
        "    cat_model.fit(feature_train_ML_scaled, target_train_ML_vectorized)\n",
        "    target_valid_ML_pred = cat_model.predict(feature_valid_ML_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(target_valid_ML_vectorized, target_valid_ML_pred))\n",
        "    print(f'max_depth: {value}, rmse: {rmse}') # 4\n",
        "\n",
        "# model parameter optimization\n",
        "for value in range(50,100):\n",
        "    param_values =  value\n",
        "    param = {'n_estimators': param_values, 'max_depth': 4, 'verbose': 0}\n",
        "\n",
        "    cat_model = cb.CatBoostRegressor(**param)\n",
        "    cat_model.fit(feature_train_ML_scaled, target_train_ML_vectorized)\n",
        "    target_valid_ML_pred = cat_model.predict(feature_valid_ML_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(target_valid_ML_vectorized, target_valid_ML_pred))\n",
        "    print(f'max_depth: {value}, rmse: {rmse}') # 87\n",
        "\n",
        "# fit xgboost\n",
        "# initialize model\n",
        "xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "# fit\n",
        "start_time = time.time()\n",
        "xgb_model.fit(feature_train_ML_scaled, target_train_ML_vectorized)\n",
        "end_time = time.time()\n",
        "xgb_train_time = end_time - start_time\n",
        "print(f'train time: {xgb_train_time}')\n",
        "\n",
        "# predict\n",
        "start_time = time.time()\n",
        "target_valid_ML_pred = xgb_model.predict(feature_valid_ML_scaled)\n",
        "end_time = time.time()\n",
        "xgb_pred_time = end_time - start_time\n",
        "print(f'pred time: {xgb_pred_time}')\n",
        "\n",
        "# score\n",
        "xgb_rmse = np.sqrt(mean_squared_error(target_valid_ML_vectorized, target_valid_ML_pred))\n",
        "print(f'rmse: {xgb_rmse}') # 3168.165462982111\n",
        "\n",
        "# observation\n",
        "# rmse is higher than lgb\n",
        "\n",
        "# final stats\n",
        "print(f'linear_rmse: {linear_rmse}\\nlgb_rmse: {lgb_rmse}\\nrfr_rmse: {rfr_rmse}\\ncat_rmse: {cat_rmse}\\nxgb_rmse:{xgb_rmse}')\n",
        "print(f'linear_train/pred: {(lr_train_time,lr_pred_time)}\\nlgb_train/pred: {(lgb_train_time,lgb_pred_time)}\\nrfr_train/pred: {(rfr_train_time,rfr_pred_time)}\\ncat_train/pred: {(cat_train_time,cat_pred_time)}\\nxgb_train/pred:{(xgb_train_time,xgb_pred_time)}')\n",
        "\n",
        "# test df\n",
        "# predict\n",
        "start_time = time.time()\n",
        "target_test_ML_pred = cat_model.predict(feature_test_ML_scaled)\n",
        "end_time = time.time()\n",
        "cat_pred_time = end_time - start_time\n",
        "print(f'pred time: {cat_pred_time}')\n",
        "\n",
        "# score\n",
        "cat_rmse = np.sqrt(mean_squared_error(target_test_ML_vectorized, target_test_ML_pred))\n",
        "print(f'rmse: {cat_rmse}') # 2237.482413986722\n",
        "\n",
        "'''\n",
        "observation\n",
        "Cat did just about the same.\n",
        "\n",
        "analysis/conclusion\n",
        "See Stats above.\n",
        "Cat model scored the best. Training time was highest for xgb, while prediction time is extremely small for all.\n",
        "I chose cat for hyperparamter optimization because it had the smallest RMSE.\n",
        "\n",
        "Conclusion: The task was to predict Price using available data. Features were reviewed one at a time and for each action in the following order:\n",
        "\n",
        "Edit values\n",
        "either correct, or identify as missing Update data types\n",
        "eg. change date from string to datetime Remove missing data\n",
        "either relabel as 'missing' or set to NA (for dropping later) Remove irrelevant columns\n",
        "drop the column if having 1:1 unique values/row, or no variation. Feature engineering\n",
        "adding columns as a function of other columns. ie. creating a month or day column from a date column.\n",
        "the data was then processed as a whole with this following actions in this order: dropped duplicate rows Drop rows with missing values Moved target to first column encoding feature scaling/vectorization target vectorization\n",
        "\n",
        "Once both features and target were in a vectorized format, we fit the following models: LinearRegression RandomForestRegressor lgb.LGBMRegressor cb.CatBoostRegressor xgb.XGBRegressor\n",
        "\n",
        "Training time, prediction time, and RMSE were measured for each model: linear_rmse: 2724.0585558060775 lgb_rmse: 2063.187614013004 rfr_rmse: 2176.8222270351207 cat_rmse: 2026.1914059369433 xgb_rmse:2236.4188514668167\n",
        "\n",
        "linear_train/pred: (0.25896334648132324, 0.025099754333496094) lgb_train/pred: (2.220857858657837, 0.04092001914978027) rfr_train/pred: (1.5917150974273682, 0.04019355773925781) cat_train/pred: (1.093503475189209, 0.0024204254150390625) xgb_train/pred:(14.426959037780762, 0.003343343734741211)\n",
        "\n",
        "CAT had he lowest RMSE. It was further lowered to when hyperparameter: 'max_depth' was optimized at 4: max_depth: 4, rmse: 2008.1364553366802\n",
        "\n",
        "It was also the second fastest model to train, so I choose CAT as the best model.\n",
        "'''\n"
      ]
    }
  ]
}